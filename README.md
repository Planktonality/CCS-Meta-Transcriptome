# CCS-Metatranscriptome

#### Metatranscriptome bioinformatic pipeline for eukaryotic phytoplankton from the California Current System.

by Yuan Yu (Johnson) Lin

## Introduction - Diatoms exhibit proactive transcriptomic response to the Upwelling Conveyor Belt Cycle (UCBC)

Phytoplankton in the California Current System (CCS) are important drivers of biogeochemical cycling and food web dynamics leading up to fish stocks and marine mammals - important aspects of the ecosystem and economy. A unique feature of the CCS is the concept of the Upwelling Conveyor Belt Cycle, which is characterized by a series of idealized zones directly related to the respective light conditions, nutrient status, and biology. Diatoms - a silicifying taxa of the CCS phytoplankton assemblage - are known to dominante the upwelling blooms in this region due to their physiological capabilities. However, our understanding of the molecular shifts within the major phytoplankton groups remain largely understudied. This study aims to address the bioinformatic tools used to assess the transcriptomic and metatranscriptomic activity of marine microalgae in response to the UCBC.

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## Bioinformatic Pipeline

### Introduction

Sequencing is a burgeoning tool used to characterize marine microorganisms in the world's oceans. As a result, phytoplankton groups are still poorly annotated given the relatively scarce reference genomes/transcriptomes out there. However, as RNA-seq is increasingly used in oceanography, our knowledge of 'omics-based tools will continue to expand. In our current state, we can still derive a great source of knowledge from the large datasets collected from the ocean environment. 

Below is a detailed breakdown of the workflow used to evaluate the metatranscriptomics of the coastal phytoplankton communities. Prior to this workflow, you will have obtained the raw reads (sample.fastq.gz) generated by Illumina HiSeq. This pipeline will be run exclusively on the Linux-based Longleaf cluster at the University of North Carolina, Chapel Hill. Each step of the pipeline may be resource intensive, so it is best to submit them as jobs using the SLURM scheduler. To do this, simply create your job file using:

``nano job.sh``

and copy and paste the below scripts into the job file.

### 1. Quality Control

The first step of the workflow will be to get rid of bad reads and adapter sequences by trimming. There is an abundance of adapter trimming tools out there, but for the purpose of our study, we will use Trim Galore. Keep in mind that the below script uses a "for" loop to perform Trim Galore on all of your samples at once.

In our scenario, we'll use 3 samples:
<br> S1 for sample 1
<br> S2 for sample 2
<br> S3 for sample 3

Additionally, take note of where your working directory will be and which directory you want your outputs to be in. Anything displayed in brackets [] here will be subject to change according to your project directory. When you actually run the code on the command line, take these brackets out.

```
#!/bin/bash

indir=[directory containing your raw reads generated by Illumina HiSeq, something like this: /proj/lab/project/raw_reads]
outdir=[directory containing your trimmed reads, something like this: /proj/lab/project/trimmed_reads]

samples='S1 S2 S3'

for s in $samples; do
        echo ${s}
	jobfile="trim${s}.sh"
	echo $jobfile
	cat <<EOF > $jobfile
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --time=0-24:00:00
#SBATCH --mem=16G
#SBATCH --ntasks=4
#SBATCH -J trim
#SBATCH -o trim.%A.out
#SBATCH -e trim.%A.err

module load trim_galore
module load pigz
echo 'BEGIN'
date
hostname
trim_galore -j 2 --illumina --paired --fastqc -o [outdirectory: /proj/lab/projects/trimmed_reads] \\
$indir/${s}_R1_001.fastq.gz \\
$indir/${s}_R2_001.fastq.gz
echo 'END'
date

EOF

sbatch $jobfile

done 
```


